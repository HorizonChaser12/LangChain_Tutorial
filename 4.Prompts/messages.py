# Here we get a knowledge on how memory concept or history concept of LangChain works. We also got to know about the types of messages in the context of development.
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv

load_dotenv()

model = ChatGoogleGenerativeAI(model='gemini-2.0-flash')

messages = [
    # SystemMessage is something that you want to just show when a user starts chating with your AI. It can even contain necessary messages or precautions that needs to be taken care of.
    SystemMessage(content="You are a helpful assistant!"),
    # HumanMessage is the query that the human wants to ask the AI about. It can be anything, be it a normal message or a structured prompt or anything.
    HumanMessage(content="Tell me how I can utilize LangChain")
]

result = model.invoke(messages)

# AImessage is more like of the output generated by the AI following the human message and the instructions given by the system designer i.e SystemMessage.
messages.append(AIMessage(content=result.content))

print(messages)


# All these things are only for the Static messages, like you arent actually generating a specialized output, rather you are just creating a conversation which is being led on through history.
# For example: SystemMessage can be  {"You are a helpful excel file analysis Assistant"}
            # This here is harcoded, like you cant change the Message even if the data is very different from what its meant to do for.
                
            # {"You are a helpful {Domain} expert}, here the domain can be changed through any kind of human intervention as well as AI and by that your query output will always be aligned to the specific domain rather than getting a unrelated output.